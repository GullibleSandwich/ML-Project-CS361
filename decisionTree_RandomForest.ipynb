{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import pprint \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = pd.read_csv('cleaned_shifted_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample the dataset\n",
    "sample_size = 50000\n",
    "sampled_df = cleaned_df\n",
    "\n",
    "# Filter relevant columns (AQI constituents)\n",
    "relevant_columns = ['PM2.5 (µg/m³)', 'PM10 (µg/m³)', 'NO (µg/m³)', 'NO2 (µg/m³)',\n",
    "                    'NOx (ppb)', 'NH3 (µg/m³)', 'SO2 (µg/m³)', 'CO (mg/m³)',\n",
    "                    'Ozone (µg/m³)']\n",
    "X = sampled_df[relevant_columns].values\n",
    "y = sampled_df['AQI_calculated_shifted'].values\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSS_reduction Function\n",
    "\n",
    "> Let RSS_parent denote the residual sum of squares (RSS) of the parent node.<br>\n",
    "> Let RSS_child_L denote the RSS of the left child node.<br>\n",
    "> Let RSS_child_R denote the RSS of the right child node.<br>\n",
    "> Then, the RSS reduction due to a split can be calculated as:<br>\n",
    "> RSS reduction = RSS_parent - (RSS_child_L + RSS_child_R)\n",
    "\n",
    "> ##### Usage: \n",
    "> This function quantifies how much the split reduces the variability (RSS) in the target variable, aiding in selecting the best split point for building the decision tree.\n",
    "\n",
    "### sort_x_by_y Function\n",
    "\n",
    "> #### Usage: \n",
    "> This function assists in finding the optimal splitting points for categorical features in decision trees by ordering the unique values of the feature according to the mean of the target variable associated with each value.\n",
    "\n",
    "### all_rows_equal Function\n",
    "\n",
    "> #### Usage: \n",
    "> This function serves as a stopping criterion in decision tree algorithms, especially for categorical features, where splits are based on equality or inequality conditions. If all rows are equal, further splitting is unnecessary, and the node can be designated as a leaf node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSS_reduction(child_L, child_R, parent):\n",
    "    rss_parent = sum((parent - np.mean(parent))**2)\n",
    "    rss_child_L = sum((child_L - np.mean(child_L))**2) \n",
    "    rss_child_R = sum((child_R - np.mean(child_R))**2)\n",
    "    return rss_parent - (rss_child_L + rss_child_R)\n",
    "\n",
    "def sort_x_by_y(x, y):\n",
    "    unique_xs = np.unique(x)\n",
    "    y_mean_by_x = np.array([y[x == unique_x].mean() for unique_x in unique_xs])\n",
    "    ordered_xs = unique_xs[np.argsort(y_mean_by_x)]\n",
    "    return ordered_xs\n",
    "\n",
    "def all_rows_equal(X):\n",
    "    return (X == X[0]).all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, Xsub, ysub, ID, depth = 0, parent_ID = None, leaf = True):\n",
    "        self.ID = ID\n",
    "        self.Xsub = Xsub\n",
    "        self.ysub = ysub\n",
    "        self.size = len(ysub)\n",
    "        self.depth = depth\n",
    "        self.parent_ID = parent_ID\n",
    "        self.leaf = leaf\n",
    "        \n",
    "class Splitter:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rss_reduction = 0\n",
    "        self.no_split = True\n",
    "        \n",
    "    def _replace_split(self, rss_reduction, d, dtype = 'quant', t = None, L_values = None):\n",
    "        self.rss_reduction = rss_reduction\n",
    "        self.d = d\n",
    "        self.dtype = dtype\n",
    "        self.t = t        \n",
    "        self.L_values = L_values     \n",
    "        self.no_split = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecisionTreeRegressor:\n",
    "\n",
    "    def __init__(self, max_depth=100, min_size=2, C=None):\n",
    "        \"\"\"\n",
    "        Initialize the Decision Tree Regressor.\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.C = C\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.N = None\n",
    "        self.D = None\n",
    "        self.dtypes = None\n",
    "        self.nodes_dict = None\n",
    "        self.current_ID = None\n",
    "        self.splitter = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.N, self.D = self.X.shape\n",
    "        dtypes = [np.array(list(self.X[:, d])).dtype for d in range(self.D)]\n",
    "        self.dtypes = ['quant' if (dtype == float or dtype == int) else 'cat' for dtype in dtypes]\n",
    "        self.nodes_dict = {}\n",
    "        self.current_ID = 0\n",
    "        initial_node = Node(Xsub=X, ysub=y, ID=self.current_ID, parent_ID=None)\n",
    "        self.nodes_dict[self.current_ID] = initial_node\n",
    "        self.current_ID += 1\n",
    "        self._build()\n",
    "    \n",
    "    def _build(self):\n",
    "        eligible_buds = self.nodes_dict \n",
    "        i=0\n",
    "        for layer in range(self.max_depth):\n",
    "            print(layer, i)\n",
    "            eligible_buds = {ID: node for (ID, node) in self.nodes_dict.items() if \n",
    "                                (node.leaf == True) &\n",
    "                                (node.size >= self.min_size) & \n",
    "                                (~all_rows_equal(node.Xsub)) &\n",
    "                                (len(np.unique(node.ysub)) > 1)}\n",
    "            if len(eligible_buds) == 0:\n",
    "                break\n",
    "            for ID, bud in eligible_buds.items():\n",
    "                self._find_split(bud)\n",
    "                if not self.splitter.no_split:\n",
    "                    self._make_split()\n",
    "            i+=1\n",
    "    \n",
    "    def _find_split(self, bud):\n",
    "        splitter = Splitter()\n",
    "        splitter.bud_ID = bud.ID\n",
    "        if self.C is None:\n",
    "            eligible_predictors = np.arange(self.D)\n",
    "        else:\n",
    "            eligible_predictors = np.random.choice(np.arange(self.D), self.C, replace=False)\n",
    "        for d in sorted(eligible_predictors):\n",
    "            Xsub_d = bud.Xsub[:, d]\n",
    "            dtype = self.dtypes[d]\n",
    "            if len(np.unique(Xsub_d)) == 1:\n",
    "                continue\n",
    "            if dtype == 'quant':\n",
    "                for t in np.unique(Xsub_d)[:-1]:\n",
    "                    ysub_L = bud.ysub[Xsub_d <= t]\n",
    "                    ysub_R = bud.ysub[Xsub_d > t]\n",
    "                    rss_reduction = RSS_reduction(ysub_L, ysub_R, bud.ysub)\n",
    "                    if rss_reduction > splitter.rss_reduction:\n",
    "                        splitter._replace_split(rss_reduction, d, dtype='quant', t=t)\n",
    "            else:\n",
    "                ordered_x = sort_x_by_y(Xsub_d, bud.ysub)\n",
    "                for i in range(len(ordered_x) - 1):\n",
    "                    L_values = ordered_x[:i+1]\n",
    "                    ysub_L = bud.ysub[np.isin(Xsub_d, L_values)]\n",
    "                    ysub_R = bud.ysub[~np.isin(Xsub_d, L_values)]\n",
    "                    rss_reduction = RSS_reduction(ysub_L, ysub_R, bud.ysub)\n",
    "                    if rss_reduction > splitter.rss_reduction: \n",
    "                        splitter._replace_split(rss_reduction, d, dtype='cat', L_values=L_values)\n",
    "        self.splitter = splitter\n",
    "    \n",
    "    def _make_split(self):\n",
    "        parent_node = self.nodes_dict[self.splitter.bud_ID]\n",
    "        parent_node.leaf = False\n",
    "        parent_node.child_L = self.current_ID\n",
    "        parent_node.child_R = self.current_ID + 1\n",
    "        parent_node.d = self.splitter.d\n",
    "        parent_node.dtype = self.splitter.dtype\n",
    "        parent_node.t = self.splitter.t        \n",
    "        parent_node.L_values = self.splitter.L_values\n",
    "        if parent_node.dtype == 'quant':\n",
    "            L_condition = parent_node.Xsub[:, parent_node.d] <= parent_node.t\n",
    "        else:\n",
    "            L_condition = np.isin(parent_node.Xsub[:, parent_node.d], parent_node.L_values)\n",
    "        Xchild_L = parent_node.Xsub[L_condition]\n",
    "        ychild_L = parent_node.ysub[L_condition]\n",
    "        Xchild_R = parent_node.Xsub[~L_condition]\n",
    "        ychild_R = parent_node.ysub[~L_condition]\n",
    "        child_node_L = Node(Xchild_L, ychild_L, depth=parent_node.depth + 1,\n",
    "                            ID=self.current_ID, parent_ID=parent_node.ID)\n",
    "        child_node_R = Node(Xchild_R, ychild_R, depth=parent_node.depth + 1,\n",
    "                            ID=self.current_ID + 1, parent_ID=parent_node.ID)\n",
    "        self.nodes_dict[self.current_ID] = child_node_L\n",
    "        self.nodes_dict[self.current_ID + 1] = child_node_R\n",
    "        self.current_ID += 2\n",
    "    \n",
    "    def _get_leaf_means(self):\n",
    "        self.leaf_means = {}\n",
    "        for node_ID, node in self.nodes_dict.items():\n",
    "            if node.leaf:\n",
    "                self.leaf_means[node_ID] = node.ysub.mean()\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        self._get_leaf_means()\n",
    "        yhat = []\n",
    "        for x in X_test:\n",
    "            node = self.nodes_dict[0] \n",
    "            while not node.leaf:\n",
    "                if node.dtype == 'quant':\n",
    "                    if x[node.d] <= node.t:\n",
    "                        node = self.nodes_dict[node.child_L]\n",
    "                    else:\n",
    "                        node = self.nodes_dict[node.child_R]\n",
    "                else:\n",
    "                    if x[node.d] in node.L_values:\n",
    "                        node = self.nodes_dict[node.child_L]\n",
    "                    else:\n",
    "                        node = self.nodes_dict[node.child_R]\n",
    "            yhat.append(self.leaf_means[node.ID])\n",
    "        return np.array(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "Mean Squared Error: 5536.125521812751\n"
     ]
    }
   ],
   "source": [
    "## Build model\n",
    "tree = DecisionTreeRegressor(max_depth = 8, min_size = 20)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3977.107086659228\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# Create a decision tree classifier model object.\n",
    "decision_tree_regressor = DecisionTreeRegressor()\n",
    "\n",
    "# Train the decision tree classifier model using the training data.\n",
    "decision_tree_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the test data.\n",
    "y_pred = decision_tree_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "mse = (mean_squared_error(y_test, y_pred))\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestRegressor:\n",
    "    \n",
    "    def __init__(self, n_estimators=10, max_depth=8, min_size=20, C=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.C = C\n",
    "        self.trees = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        i=0\n",
    "        for _ in range(self.n_estimators):\n",
    "            print(i)\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth, min_size=self.min_size, C=self.C)\n",
    "            indices = np.random.choice(len(X), len(X), replace=True)  # Bootstrap sampling\n",
    "            X_bootstrap, y_bootstrap = X[indices], y[indices]\n",
    "            tree.fit(X_bootstrap, y_bootstrap)\n",
    "            self.trees.append(tree)\n",
    "            i+=1\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        predictions = np.zeros((len(X_test), len(self.trees)))\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            predictions[:, i] = tree.predict(X_test)\n",
    "        return np.mean(predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m random_forest \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, min_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Fit the random forest model to the training data\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mrandom_forest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Make predictions on the test data\u001b[39;00m\n\u001b[0;32m      8\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m random_forest\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "Cell \u001b[1;32mIn[15], line 17\u001b[0m, in \u001b[0;36mRandomForestRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     15\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(X), \u001b[38;5;28mlen\u001b[39m(X), replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Bootstrap sampling\u001b[39;00m\n\u001b[0;32m     16\u001b[0m X_bootstrap, y_bootstrap \u001b[38;5;241m=\u001b[39m X[indices], y[indices]\n\u001b[1;32m---> 17\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_bootstrap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_bootstrap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees\u001b[38;5;241m.\u001b[39mappend(tree)\n\u001b[0;32m     19\u001b[0m i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[14], line 30\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_ID] \u001b[38;5;241m=\u001b[39m initial_node\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_ID \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 45\u001b[0m, in \u001b[0;36mDecisionTreeRegressor._build\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ID, bud \u001b[38;5;129;01min\u001b[39;00m eligible_buds\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbud\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39mno_split:\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_split()\n",
      "Cell \u001b[1;32mIn[14], line 66\u001b[0m, in \u001b[0;36mDecisionTreeRegressor._find_split\u001b[1;34m(self, bud)\u001b[0m\n\u001b[0;32m     64\u001b[0m ysub_L \u001b[38;5;241m=\u001b[39m bud\u001b[38;5;241m.\u001b[39mysub[Xsub_d \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m t]\n\u001b[0;32m     65\u001b[0m ysub_R \u001b[38;5;241m=\u001b[39m bud\u001b[38;5;241m.\u001b[39mysub[Xsub_d \u001b[38;5;241m>\u001b[39m t]\n\u001b[1;32m---> 66\u001b[0m rss_reduction \u001b[38;5;241m=\u001b[39m \u001b[43mRSS_reduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mysub_L\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mysub_R\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbud\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mysub\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rss_reduction \u001b[38;5;241m>\u001b[39m splitter\u001b[38;5;241m.\u001b[39mrss_reduction:\n\u001b[0;32m     68\u001b[0m     splitter\u001b[38;5;241m.\u001b[39m_replace_split(rss_reduction, d, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquant\u001b[39m\u001b[38;5;124m'\u001b[39m, t\u001b[38;5;241m=\u001b[39mt)\n",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m, in \u001b[0;36mRSS_reduction\u001b[1;34m(child_L, child_R, parent)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mRSS_reduction\u001b[39m(child_L, child_R, parent):\n\u001b[0;32m      2\u001b[0m     rss_parent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m((parent \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(parent))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     rss_child_L \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m((child_L \u001b[38;5;241m-\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild_L\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \n\u001b[0;32m      4\u001b[0m     rss_child_R \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m((child_R \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(child_R))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rss_parent \u001b[38;5;241m-\u001b[39m (rss_child_L \u001b[38;5;241m+\u001b[39m rss_child_R)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3437\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3438\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _methods\u001b[38;5;241m.\u001b[39m_mean(a, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   3441\u001b[0m                       out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:179\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    176\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    177\u001b[0m         is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    181\u001b[0m     ret \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mtrue_divide(\n\u001b[0;32m    182\u001b[0m             ret, rcount, out\u001b[38;5;241m=\u001b[39mret, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the random forest regressor\n",
    "random_forest = RandomForestRegressor(n_estimators=10, max_depth=8, min_size=20, C=None)\n",
    "\n",
    "# Fit the random forest model to the training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model (e.g., using mean squared error)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (scikit-learn RandomForestRegressor): 4904.857105884316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the random forest regressor\n",
    "sklearn_random_forest = RandomForestRegressor(n_estimators=10, max_depth=8, min_samples_split=2)\n",
    "\n",
    "# Fit the random forest model to the training data\n",
    "sklearn_random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_sklearn = sklearn_random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the scikit-learn random forest model (e.g., using mean squared error)\n",
    "mse_sklearn = mean_squared_error(y_test, y_pred_sklearn)\n",
    "print(\"Mean Squared Error (scikit-learn RandomForestRegressor):\", mse_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
