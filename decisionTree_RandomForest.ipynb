{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import pprint \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = pd.read_csv('/cleaned_shifted_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample the dataset\n",
    "sample_size = 10000\n",
    "sampled_df = cleaned_df.sample(n=sample_size, random_state=11)\n",
    "\n",
    "# Filter relevant columns (AQI constituents)\n",
    "relevant_columns = ['PM2.5 (µg/m³)', 'PM10 (µg/m³)', 'NO (µg/m³)', 'NO2 (µg/m³)',\n",
    "                    'NOx (ppb)', 'NH3 (µg/m³)', 'SO2 (µg/m³)', 'CO (mg/m³)',\n",
    "                    'Ozone (µg/m³)']\n",
    "X = cleaned_df[relevant_columns].values\n",
    "y = cleaned_df['AQI_calculated_shifted'].values\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSS_reduction(child_L, child_R, parent):\n",
    "    rss_parent = sum((parent - np.mean(parent))**2)\n",
    "    rss_child_L = sum((child_L - np.mean(child_L))**2) \n",
    "    rss_child_R = sum((child_R - np.mean(child_R))**2)\n",
    "    return rss_parent - (rss_child_L + rss_child_R)\n",
    "\n",
    "def sort_x_by_y(x, y):\n",
    "    unique_xs = np.unique(x)\n",
    "    y_mean_by_x = np.array([y[x == unique_x].mean() for unique_x in unique_xs])\n",
    "    ordered_xs = unique_xs[np.argsort(y_mean_by_x)]\n",
    "    return ordered_xs\n",
    "\n",
    "def all_rows_equal(X):\n",
    "    return (X == X[0]).all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Timestamp  Unnamed: 0        Station  PM2.5 (µg/m³)  \\\n",
      "232903  2023-12-06 09:00:00      383076  LGBI Airport           144.0   \n",
      "232904  2023-12-06 09:15:00      383077  LGBI Airport           144.0   \n",
      "232905  2023-12-06 09:30:00      383078  LGBI Airport           144.0   \n",
      "232906  2023-12-06 09:45:00      383079  LGBI Airport           144.0   \n",
      "232907  2023-12-06 10:00:00      383080  LGBI Airport           144.0   \n",
      "232908  2023-12-06 10:15:00      383081  LGBI Airport           144.0   \n",
      "232909  2023-12-06 10:30:00      383082  LGBI Airport           144.0   \n",
      "232910  2023-12-06 11:45:00      383087  LGBI Airport           170.0   \n",
      "232911  2023-12-06 12:00:00      383088  LGBI Airport           170.0   \n",
      "232912  2023-12-06 12:15:00      383089  LGBI Airport           170.0   \n",
      "232913  2023-12-06 12:30:00      383090  LGBI Airport           170.0   \n",
      "232914  2023-12-06 13:45:00      383095  LGBI Airport            89.0   \n",
      "232915  2023-12-06 14:00:00      383096  LGBI Airport            87.0   \n",
      "232916  2023-12-06 14:15:00      383097  LGBI Airport            87.0   \n",
      "232917  2023-12-06 14:30:00      383098  LGBI Airport            87.0   \n",
      "232918  2023-12-06 14:45:00      383099  LGBI Airport            72.0   \n",
      "232919  2023-12-06 15:00:00      383100  LGBI Airport            71.0   \n",
      "232920  2023-12-06 15:15:00      383101  LGBI Airport            71.0   \n",
      "232921  2023-12-06 16:30:00      383106  LGBI Airport            73.0   \n",
      "232922  2023-12-06 17:15:00      383109  LGBI Airport            70.0   \n",
      "\n",
      "        PM10 (µg/m³)  NO (µg/m³)  NO2 (µg/m³)  NOx (ppb)  NH3 (µg/m³)  \\\n",
      "232903         185.0         7.3          6.1        9.2          6.4   \n",
      "232904         185.0         7.2          6.2        9.1          6.4   \n",
      "232905         185.0         6.8          5.9        8.7          6.1   \n",
      "232906         188.0         6.6          5.9        8.6          6.0   \n",
      "232907         188.0         6.6          6.1        8.6          6.0   \n",
      "232908         188.0         6.6          6.0        8.5          6.0   \n",
      "232909         188.0         6.6          5.9        8.5          6.0   \n",
      "232910         205.0         6.5          4.4        7.6          5.3   \n",
      "232911         218.0         6.5          3.9        7.3          5.1   \n",
      "232912         218.0         6.5          3.8        7.3          5.1   \n",
      "232913         218.0         6.4          3.6        7.2          5.0   \n",
      "232914         118.0         6.5          2.9        6.8          4.8   \n",
      "232915         125.0         6.4          2.8        6.7          4.7   \n",
      "232916         125.0         6.4          2.7        6.6          4.6   \n",
      "232917         125.0         6.4          2.8        6.7          4.7   \n",
      "232918         116.0         6.4          3.3        6.9          4.9   \n",
      "232919         114.0         6.4          3.4        7.0          4.9   \n",
      "232920         114.0         6.3          3.5        7.0          4.9   \n",
      "232921         114.0         6.3          5.0        7.8          5.5   \n",
      "232922         230.0         6.3          5.7        8.2          5.7   \n",
      "\n",
      "        SO2 (µg/m³)  CO (mg/m³)  Ozone (µg/m³)  Checks  AQI_calculated  \\\n",
      "232903         40.3        0.95           36.0       7           256.0   \n",
      "232904         27.6        1.02           43.4       7           254.0   \n",
      "232905         26.9        1.02           51.5       7           253.0   \n",
      "232906         36.1        1.04           58.4       7           252.0   \n",
      "232907         44.6        1.08           57.4       7           251.0   \n",
      "232908         44.1        1.09           56.3       7           251.0   \n",
      "232909         43.9        1.12           55.6       7           250.0   \n",
      "232910         30.5        0.88           70.5       7           251.0   \n",
      "232911         35.1        0.82           72.9       7           254.0   \n",
      "232912         27.4        0.82           78.3       7           257.0   \n",
      "232913         21.4        0.85           80.3       7           259.0   \n",
      "232914         42.1        0.70           85.6       7           257.0   \n",
      "232915         39.6        0.68           79.8       7           256.0   \n",
      "232916         48.0        0.64           75.9       7           255.0   \n",
      "232917         31.0        0.64           72.3       7           254.0   \n",
      "232918         44.2        0.63           68.0       7           252.0   \n",
      "232919         41.3        0.68           69.1       7           249.0   \n",
      "232920         42.2        0.73           66.9       7           247.0   \n",
      "232921          0.4        0.76           44.6       7           238.0   \n",
      "232922          0.2        0.79           36.5       7           227.0   \n",
      "\n",
      "       AQI_bucket_calculated  AQI_calculated_shifted  \\\n",
      "232903                  Poor                   206.0   \n",
      "232904                  Poor                   207.0   \n",
      "232905                  Poor                   207.0   \n",
      "232906                  Poor                   208.0   \n",
      "232907                  Poor                   209.0   \n",
      "232908                  Poor                   211.0   \n",
      "232909                  Poor                   212.0   \n",
      "232910                  Poor                   214.0   \n",
      "232911                  Poor                   215.0   \n",
      "232912                  Poor                   215.0   \n",
      "232913                  Poor                   215.0   \n",
      "232914                  Poor                   217.0   \n",
      "232915                  Poor                   218.0   \n",
      "232916                  Poor                   219.0   \n",
      "232917                  Poor                   219.0   \n",
      "232918                  Poor                   219.0   \n",
      "232919                  Poor                   219.0   \n",
      "232920                  Poor                   219.0   \n",
      "232921                  Poor                   220.0   \n",
      "232922                  Poor                   220.0   \n",
      "\n",
      "       AQI_bucket_calculated_shifted  \n",
      "232903                          Poor  \n",
      "232904                          Poor  \n",
      "232905                          Poor  \n",
      "232906                          Poor  \n",
      "232907                          Poor  \n",
      "232908                          Poor  \n",
      "232909                          Poor  \n",
      "232910                          Poor  \n",
      "232911                          Poor  \n",
      "232912                          Poor  \n",
      "232913                          Poor  \n",
      "232914                          Poor  \n",
      "232915                          Poor  \n",
      "232916                          Poor  \n",
      "232917                          Poor  \n",
      "232918                          Poor  \n",
      "232919                          Poor  \n",
      "232920                          Poor  \n",
      "232921                          Poor  \n",
      "232922                          Poor  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Timestamp', 'Unnamed: 0', 'Station', 'PM2.5 (µg/m³)', 'PM10 (µg/m³)',\n",
       "       'NO (µg/m³)', 'NO2 (µg/m³)', 'NOx (ppb)', 'NH3 (µg/m³)', 'SO2 (µg/m³)',\n",
       "       'CO (mg/m³)', 'Ozone (µg/m³)', 'Checks', 'AQI_calculated',\n",
       "       'AQI_bucket_calculated', 'AQI_calculated_shifted',\n",
       "       'AQI_bucket_calculated_shifted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, Xsub, ysub, ID, depth = 0, parent_ID = None, leaf = True):\n",
    "        self.ID = ID\n",
    "        self.Xsub = Xsub\n",
    "        self.ysub = ysub\n",
    "        self.size = len(ysub)\n",
    "        self.depth = depth\n",
    "        self.parent_ID = parent_ID\n",
    "        self.leaf = leaf\n",
    "        \n",
    "class Splitter:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rss_reduction = 0\n",
    "        self.no_split = True\n",
    "        \n",
    "    def _replace_split(self, rss_reduction, d, dtype = 'quant', t = None, L_values = None):\n",
    "        self.rss_reduction = rss_reduction\n",
    "        self.d = d\n",
    "        self.dtype = dtype\n",
    "        self.t = t        \n",
    "        self.L_values = L_values     \n",
    "        self.no_split = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVR with linear kernel\n"
     ]
    }
   ],
   "source": [
    "class DecisionTreeRegressor:\n",
    "    \n",
    "    def __init__(self, max_depth=100, min_size=2, C=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.C = C\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.N, self.D = self.X.shape\n",
    "        dtypes = [np.array(list(self.X[:, d])).dtype for d in range(self.D)]\n",
    "        self.dtypes = ['quant' if (dtype == float or dtype == int) else 'cat' for dtype in dtypes]\n",
    "        self.nodes_dict = {}\n",
    "        self.current_ID = 0\n",
    "        initial_node = Node(Xsub=X, ysub=y, ID=self.current_ID, parent_ID=None)\n",
    "        self.nodes_dict[self.current_ID] = initial_node\n",
    "        self.current_ID += 1\n",
    "        self._build()\n",
    "    \n",
    "    # Buld the decision tree\n",
    "    def _build(self):\n",
    "\n",
    "        eligible_buds = self.nodes_dict\n",
    "        current_depth = 0\n",
    "        while current_depth < self.max_depth:\n",
    "            current_depth += 1\n",
    "            eligible_buds = {ID: node for (ID, node) in self.nodes_dict.items() if \n",
    "                                (node.leaf == True) &\n",
    "                                (node.size >= self.min_size) & \n",
    "                                (~all_rows_equal(node.Xsub)) &\n",
    "                                (len(np.unique(node.ysub)) > 1)}\n",
    "            if len(eligible_buds) == 0:\n",
    "                break\n",
    "            for ID, bud in eligible_buds.items():\n",
    "                self._find_split(bud)\n",
    "                if not self.splitter.no_split:\n",
    "                    self._make_split()\n",
    "\n",
    "    \n",
    "    # Find the best split for a node\n",
    "    def _find_split(self, bud):\n",
    "        splitter = Splitter()\n",
    "        splitter.bud_ID = bud.ID\n",
    "        eligible_predictors = np.random.permutation(np.arange(self.D))[:self.C] if self.C is not None else np.arange(self.D)\n",
    "        \n",
    "        for predictor in eligible_predictors:\n",
    "            X_sub = bud.Xsub[:, predictor]\n",
    "            dtype = self.dtypes[predictor]\n",
    "            \n",
    "            if len(np.unique(X_sub)) == 1:\n",
    "                continue\n",
    "            \n",
    "            if dtype == 'quant':\n",
    "                thresholds = np.linspace(np.min(X_sub), np.max(X_sub), num=self.C + 1)[1:-1]\n",
    "                best_rss_reduction = -np.inf\n",
    "                best_threshold = None\n",
    "                \n",
    "                for threshold in thresholds:\n",
    "                    y_sub_L = bud.ysub[X_sub <= threshold]\n",
    "                    y_sub_R = bud.ysub[X_sub > threshold]\n",
    "                    rss_reduction = RSS_reduction(y_sub_L, y_sub_R, bud.ysub)\n",
    "                    \n",
    "                    if rss_reduction > best_rss_reduction:\n",
    "                        best_rss_reduction = rss_reduction\n",
    "                        best_threshold = threshold\n",
    "                        \n",
    "                if best_rss_reduction > splitter.rss_reduction:\n",
    "                    splitter._replace_split(best_rss_reduction, predictor, dtype='quant', t=best_threshold)\n",
    "            \n",
    "            else:\n",
    "                ordered_values = sort_x_by_y(X_sub, bud.ysub)\n",
    "                num_splits = min(self.C, len(ordered_values) - 1)\n",
    "                split_indices = np.random.choice(np.arange(1, len(ordered_values)), size=num_splits, replace=False)\n",
    "                \n",
    "                for index in split_indices:\n",
    "                    L_values = ordered_values[:index]\n",
    "                    y_sub_L = bud.ysub[np.isin(X_sub, L_values)]\n",
    "                    y_sub_R = bud.ysub[~np.isin(X_sub, L_values)]\n",
    "                    rss_reduction = RSS_reduction(y_sub_L, y_sub_R, bud.ysub)\n",
    "                    \n",
    "                    if rss_reduction > splitter.rss_reduction:\n",
    "                        splitter._replace_split(rss_reduction, predictor, dtype='cat', L_values=L_values)\n",
    "        \n",
    "        self.splitter = splitter\n",
    "\n",
    "    # Make split\n",
    "    def _make_split(self):\n",
    "        \"\"\"\n",
    "        Make a split based on the best split found.\n",
    "        \"\"\"\n",
    "        parent_node = self.nodes_dict[self.splitter.bud_ID]\n",
    "        parent_node.leaf = False\n",
    "        parent_node.child_L = self.current_ID\n",
    "        parent_node.child_R = self.current_ID + 1\n",
    "        parent_node.d = self.splitter.d\n",
    "        parent_node.dtype = self.splitter.dtype\n",
    "        parent_node.t = self.splitter.t        \n",
    "        parent_node.L_values = self.splitter.L_values\n",
    "        \n",
    "        X_sub = parent_node.Xsub[:, parent_node.d]\n",
    "        \n",
    "        if parent_node.dtype == 'quant':\n",
    "            L_condition = X_sub <= parent_node.t\n",
    "        else:\n",
    "            L_condition = np.isin(X_sub, parent_node.L_values)\n",
    "        \n",
    "        Xchild_L = parent_node.Xsub[L_condition]\n",
    "        ychild_L = parent_node.ysub[L_condition]\n",
    "        Xchild_R = parent_node.Xsub[~L_condition]\n",
    "        ychild_R = parent_node.ysub[~L_condition]\n",
    "        \n",
    "        child_node_L = Node(Xchild_L, ychild_L, depth=parent_node.depth + 1,\n",
    "                            ID=self.current_ID, parent_ID=parent_node.ID)\n",
    "        child_node_R = Node(Xchild_R, ychild_R, depth=parent_node.depth + 1,\n",
    "                            ID=self.current_ID + 1, parent_ID=parent_node.ID)\n",
    "        \n",
    "        self.nodes_dict[self.current_ID] = child_node_L\n",
    "        self.nodes_dict[self.current_ID + 1] = child_node_R\n",
    "        self.current_ID += 2\n",
    "\n",
    "\n",
    "        # Get leaf node means\n",
    "        def _get_leaf_means(self):\n",
    "            self.leaf_means = {}\n",
    "            for node_ID, node in self.nodes_dict.items():\n",
    "                if node.leaf:\n",
    "                    self.leaf_means[node_ID] = node.ysub.mean()\n",
    "\n",
    "        # Predict using the trained decision tree\n",
    "        def predict(self, X_test):\n",
    "            self._get_leaf_means()\n",
    "            yhat = []\n",
    "            for x in X_test:\n",
    "                node = self.nodes_dict[0] \n",
    "                while not node.leaf:\n",
    "                    if node.dtype == 'quant':\n",
    "                        if x[node.d] <= node.t:\n",
    "                            node = self.nodes_dict[node.child_L]\n",
    "                        else:\n",
    "                            node = self.nodes_dict[node.child_R]\n",
    "                    else:\n",
    "                        if x[node.d] in node.L_values:\n",
    "                            node = self.nodes_dict[node.child_L]\n",
    "                        else:\n",
    "                            node = self.nodes_dict[node.child_R]\n",
    "                yhat.append(self.leaf_means[node.ID])\n",
    "            return np.array(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build model\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train, y_train, max_depth = 7, min_size = 5)\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# Create a decision tree classifier model object.\n",
    "decision_tree_regressor = DecisionTreeRegressor()\n",
    "\n",
    "# Train the decision tree classifier model using the training data.\n",
    "decision_tree_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the test data.\n",
    "y_pred = decision_tree_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "mse = (mean_squared_error(y_test, y_pred))\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestRegressor:\n",
    "    \n",
    "    def __init__(self, n_estimators=10, max_depth=100, min_size=2, C=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.C = C\n",
    "        self.trees = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.n_estimators):\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth, min_size=self.min_size, C=self.C)\n",
    "            indices = np.random.choice(len(X), len(X), replace=True)  # Bootstrap sampling\n",
    "            X_bootstrap, y_bootstrap = X[indices], y[indices]\n",
    "            tree.fit(X_bootstrap, y_bootstrap)\n",
    "            self.trees.append(tree)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        predictions = np.zeros((len(X_test), len(self.trees)))\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            predictions[:, i] = tree.predict(X_test)\n",
    "        return np.mean(predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the random forest regressor\n",
    "random_forest = RandomForestRegressor(n_estimators=10, max_depth=100, min_size=2, C=None)\n",
    "\n",
    "# Fit the random forest model to the training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model (e.g., using mean squared error)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the random forest regressor\n",
    "sklearn_random_forest = RandomForestRegressor(n_estimators=10, max_depth=100, min_samples_split=2)\n",
    "\n",
    "# Fit the random forest model to the training data\n",
    "sklearn_random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_sklearn = sklearn_random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the scikit-learn random forest model (e.g., using mean squared error)\n",
    "mse_sklearn = mean_squared_error(y_test, y_pred_sklearn)\n",
    "print(\"Mean Squared Error (scikit-learn RandomForestRegressor):\", mse_sklearn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
