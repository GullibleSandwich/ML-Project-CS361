{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Himanshi\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\Himanshi\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n",
      "C:\\Users\\Himanshi\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import pprint \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = pd.read_csv('cleaned_shifted_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample the dataset\n",
    "sample_size = 1000\n",
    "sampled_df = cleaned_df.sample(n=sample_size, random_state=11)\n",
    "\n",
    "# Filter relevant columns (AQI constituents)\n",
    "relevant_columns = ['PM2.5 (µg/m³)', 'PM10 (µg/m³)', 'NO (µg/m³)', 'NO2 (µg/m³)',\n",
    "                    'NOx (ppb)', 'NH3 (µg/m³)', 'SO2 (µg/m³)', 'CO (mg/m³)',\n",
    "                    'Ozone (µg/m³)']\n",
    "X = sampled_df[relevant_columns].values\n",
    "y = sampled_df['AQI_calculated_shifted'].values\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSS_reduction Function\n",
    "\n",
    "> Let RSS_parent denote the residual sum of squares (RSS) of the parent node.<br>\n",
    "> Let RSS_child_L denote the RSS of the left child node.<br>\n",
    "> Let RSS_child_R denote the RSS of the right child node.<br>\n",
    "> Then, the RSS reduction due to a split can be calculated as:<br>\n",
    "> RSS reduction = RSS_parent - (RSS_child_L + RSS_child_R)\n",
    "\n",
    "> ##### Usage: \n",
    "> This function quantifies how much the split reduces the variability (RSS) in the target variable, aiding in selecting the best split point for building the decision tree.\n",
    "\n",
    "### sort_x_by_y Function\n",
    "\n",
    "> #### Usage: \n",
    "> This function assists in finding the optimal splitting points for categorical features in decision trees by ordering the unique values of the feature according to the mean of the target variable associated with each value.\n",
    "\n",
    "### all_rows_equal Function\n",
    "\n",
    "> #### Usage: \n",
    "> This function serves as a stopping criterion in decision tree algorithms, especially for categorical features, where splits are based on equality or inequality conditions. If all rows are equal, further splitting is unnecessary, and the node can be designated as a leaf node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSS_reduction(child_L, child_R, parent):\n",
    "    rss_parent = sum((parent - np.mean(parent))**2)\n",
    "    rss_child_L = sum((child_L - np.mean(child_L))**2) \n",
    "    rss_child_R = sum((child_R - np.mean(child_R))**2)\n",
    "    return rss_parent - (rss_child_L + rss_child_R)\n",
    "\n",
    "def sort_x_by_y(x, y):\n",
    "    unique_xs = np.unique(x)\n",
    "    y_mean_by_x = np.array([y[x == unique_x].mean() for unique_x in unique_xs])\n",
    "    ordered_xs = unique_xs[np.argsort(y_mean_by_x)]\n",
    "    return ordered_xs\n",
    "\n",
    "def all_rows_equal(X):\n",
    "    return (X == X[0]).all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, Xsub, ysub, ID, depth = 0, parent_ID = None, leaf = True):\n",
    "        self.ID = ID\n",
    "        self.Xsub = Xsub\n",
    "        self.ysub = ysub\n",
    "        self.size = len(ysub)\n",
    "        self.depth = depth\n",
    "        self.parent_ID = parent_ID\n",
    "        self.leaf = leaf\n",
    "        \n",
    "class Splitter:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rss_reduction = 0\n",
    "        self.no_split = True\n",
    "        \n",
    "    def _replace_split(self, rss_reduction, d, dtype = 'quant', t = None, L_values = None):\n",
    "        self.rss_reduction = rss_reduction\n",
    "        self.d = d\n",
    "        self.dtype = dtype\n",
    "        self.t = t        \n",
    "        self.L_values = L_values     \n",
    "        self.no_split = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecisionTreeRegressor:\n",
    "\n",
    "    def __init__(self, max_depth=100, min_size=2, C=None):\n",
    "        \"\"\"\n",
    "        Initialize the Decision Tree Regressor.\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.C = C\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.N = None\n",
    "        self.D = None\n",
    "        self.dtypes = None\n",
    "        self.nodes_dict = None\n",
    "        self.current_ID = None\n",
    "        self.splitter = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.N, self.D = self.X.shape\n",
    "        dtypes = [np.array(list(self.X[:, d])).dtype for d in range(self.D)]\n",
    "        self.dtypes = ['quant' if (dtype == float or dtype == int) else 'cat' for dtype in dtypes]\n",
    "        self.nodes_dict = {}\n",
    "        self.current_ID = 0\n",
    "        initial_node = Node(Xsub=X, ysub=y, ID=self.current_ID, parent_ID=None)\n",
    "        self.nodes_dict[self.current_ID] = initial_node\n",
    "        self.current_ID += 1\n",
    "        self._build()\n",
    "    \n",
    "    def _build(self):\n",
    "        eligible_buds = self.nodes_dict \n",
    "        i=0\n",
    "        for layer in range(self.max_depth):\n",
    "            print(layer, i)\n",
    "            eligible_buds = {ID: node for (ID, node) in self.nodes_dict.items() if \n",
    "                                (node.leaf == True) &\n",
    "                                (node.size >= self.min_size) & \n",
    "                                (~all_rows_equal(node.Xsub)) &\n",
    "                                (len(np.unique(node.ysub)) > 1)}\n",
    "            if len(eligible_buds) == 0:\n",
    "                break\n",
    "            for ID, bud in eligible_buds.items():\n",
    "                self._find_split(bud)\n",
    "                if not self.splitter.no_split:\n",
    "                    self._make_split()\n",
    "            i+=1\n",
    "    \n",
    "    def _find_split(self, bud):\n",
    "        splitter = Splitter()\n",
    "        splitter.bud_ID = bud.ID\n",
    "        if self.C is None:\n",
    "            eligible_predictors = np.arange(self.D)\n",
    "        else:\n",
    "            eligible_predictors = np.random.choice(np.arange(self.D), self.C, replace=False)\n",
    "        for d in sorted(eligible_predictors):\n",
    "            Xsub_d = bud.Xsub[:, d]\n",
    "            dtype = self.dtypes[d]\n",
    "            if len(np.unique(Xsub_d)) == 1:\n",
    "                continue\n",
    "            if dtype == 'quant':\n",
    "                for t in np.unique(Xsub_d)[:-1]:\n",
    "                    ysub_L = bud.ysub[Xsub_d <= t]\n",
    "                    ysub_R = bud.ysub[Xsub_d > t]\n",
    "                    rss_reduction = RSS_reduction(ysub_L, ysub_R, bud.ysub)\n",
    "                    if rss_reduction > splitter.rss_reduction:\n",
    "                        splitter._replace_split(rss_reduction, d, dtype='quant', t=t)\n",
    "            else:\n",
    "                ordered_x = sort_x_by_y(Xsub_d, bud.ysub)\n",
    "                for i in range(len(ordered_x) - 1):\n",
    "                    L_values = ordered_x[:i+1]\n",
    "                    ysub_L = bud.ysub[np.isin(Xsub_d, L_values)]\n",
    "                    ysub_R = bud.ysub[~np.isin(Xsub_d, L_values)]\n",
    "                    rss_reduction = RSS_reduction(ysub_L, ysub_R, bud.ysub)\n",
    "                    if rss_reduction > splitter.rss_reduction: \n",
    "                        splitter._replace_split(rss_reduction, d, dtype='cat', L_values=L_values)\n",
    "        self.splitter = splitter\n",
    "    \n",
    "    def _make_split(self):\n",
    "        parent_node = self.nodes_dict[self.splitter.bud_ID]\n",
    "        parent_node.leaf = False\n",
    "        parent_node.child_L = self.current_ID\n",
    "        parent_node.child_R = self.current_ID + 1\n",
    "        parent_node.d = self.splitter.d\n",
    "        parent_node.dtype = self.splitter.dtype\n",
    "        parent_node.t = self.splitter.t        \n",
    "        parent_node.L_values = self.splitter.L_values\n",
    "        if parent_node.dtype == 'quant':\n",
    "            L_condition = parent_node.Xsub[:, parent_node.d] <= parent_node.t\n",
    "        else:\n",
    "            L_condition = np.isin(parent_node.Xsub[:, parent_node.d], parent_node.L_values)\n",
    "        Xchild_L = parent_node.Xsub[L_condition]\n",
    "        ychild_L = parent_node.ysub[L_condition]\n",
    "        Xchild_R = parent_node.Xsub[~L_condition]\n",
    "        ychild_R = parent_node.ysub[~L_condition]\n",
    "        child_node_L = Node(Xchild_L, ychild_L, depth=parent_node.depth + 1,\n",
    "                            ID=self.current_ID, parent_ID=parent_node.ID)\n",
    "        child_node_R = Node(Xchild_R, ychild_R, depth=parent_node.depth + 1,\n",
    "                            ID=self.current_ID + 1, parent_ID=parent_node.ID)\n",
    "        self.nodes_dict[self.current_ID] = child_node_L\n",
    "        self.nodes_dict[self.current_ID + 1] = child_node_R\n",
    "        self.current_ID += 2\n",
    "    \n",
    "    def _get_leaf_means(self):\n",
    "        self.leaf_means = {}\n",
    "        for node_ID, node in self.nodes_dict.items():\n",
    "            if node.leaf:\n",
    "                self.leaf_means[node_ID] = node.ysub.mean()\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        self._get_leaf_means()\n",
    "        yhat = []\n",
    "        for x in X_test:\n",
    "            node = self.nodes_dict[0] \n",
    "            while not node.leaf:\n",
    "                if node.dtype == 'quant':\n",
    "                    if x[node.d] <= node.t:\n",
    "                        node = self.nodes_dict[node.child_L]\n",
    "                    else:\n",
    "                        node = self.nodes_dict[node.child_R]\n",
    "                else:\n",
    "                    if x[node.d] in node.L_values:\n",
    "                        node = self.nodes_dict[node.child_L]\n",
    "                    else:\n",
    "                        node = self.nodes_dict[node.child_R]\n",
    "            yhat.append(self.leaf_means[node.ID])\n",
    "        return np.array(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build model\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train, y_train, max_depth = 7, min_size = 5)\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3977.107086659228\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# Create a decision tree classifier model object.\n",
    "decision_tree_regressor = DecisionTreeRegressor()\n",
    "\n",
    "# Train the decision tree classifier model using the training data.\n",
    "decision_tree_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the test data.\n",
    "y_pred = decision_tree_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "mse = (mean_squared_error(y_test, y_pred))\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestRegressor:\n",
    "    \n",
    "    def __init__(self, n_estimators=10, max_depth=100, min_size=2, C=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.C = C\n",
    "        self.trees = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        i=0\n",
    "        for _ in range(self.n_estimators):\n",
    "            print(i)\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth, min_size=self.min_size, C=self.C)\n",
    "            indices = np.random.choice(len(X), len(X), replace=True)  # Bootstrap sampling\n",
    "            X_bootstrap, y_bootstrap = X[indices], y[indices]\n",
    "            tree.fit(X_bootstrap, y_bootstrap)\n",
    "            self.trees.append(tree)\n",
    "            i+=1\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        predictions = np.zeros((len(X_test), len(self.trees)))\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            predictions[:, i] = tree.predict(X_test)\n",
    "        return np.mean(predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "20 20\n",
      "21 21\n",
      "22 22\n",
      "23 23\n",
      "1\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "20 20\n",
      "21 21\n",
      "22 22\n",
      "23 23\n",
      "24 24\n",
      "2\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "20 20\n",
      "21 21\n",
      "22 22\n",
      "3\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "20 20\n",
      "21 21\n",
      "4\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "20 20\n",
      "21 21\n",
      "22 22\n",
      "23 23\n",
      "5\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "20 20\n",
      "21 21\n",
      "22 22\n",
      "23 23\n",
      "24 24\n",
      "25 25\n",
      "6\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "20 20\n",
      "21 21\n",
      "22 22\n",
      "23 23\n",
      "24 24\n",
      "25 25\n",
      "26 26\n",
      "27 27\n",
      "7\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "8\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "20 20\n",
      "21 21\n",
      "22 22\n",
      "23 23\n",
      "24 24\n",
      "25 25\n",
      "26 26\n",
      "27 27\n",
      "9\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "20 20\n",
      "21 21\n",
      "22 22\n",
      "Mean Squared Error: 7872.2133\n"
     ]
    }
   ],
   "source": [
    "# Initialize the random forest regressor\n",
    "random_forest = RandomForestRegressor(n_estimators=10, max_depth=100, min_size=2, C=None)\n",
    "\n",
    "# Fit the random forest model to the training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model (e.g., using mean squared error)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (scikit-learn RandomForestRegressor): 2302.0812545418135\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the random forest regressor\n",
    "sklearn_random_forest = RandomForestRegressor(n_estimators=10, max_depth=100, min_samples_split=2)\n",
    "\n",
    "# Fit the random forest model to the training data\n",
    "sklearn_random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_sklearn = sklearn_random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the scikit-learn random forest model (e.g., using mean squared error)\n",
    "mse_sklearn = mean_squared_error(y_test, y_pred_sklearn)\n",
    "print(\"Mean Squared Error (scikit-learn RandomForestRegressor):\", mse_sklearn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
