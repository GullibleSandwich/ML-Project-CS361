{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA manual implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we implement Principal Component Analysis (or dimensionality reduction) for feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    \n",
    "    def __init__(self, num_components):\n",
    "        self.num_components = num_components\n",
    "        self.components     = None\n",
    "        self.mean           = None\n",
    "        self.variance_share = None\n",
    "    \n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Find principal components\n",
    "        \"\"\"\n",
    "        \n",
    "        # data centering\n",
    "        self.mean = np.mean(X, axis = 0)\n",
    "        X        -= self.mean\n",
    "        \n",
    "        # calculate eigenvalues & vectors\n",
    "        cov_matrix      = np.cov(X.T)\n",
    "        values, vectors = np.linalg.eig(cov_matrix)\n",
    "        \n",
    "        # sort eigenvalues & vectors \n",
    "        sort_idx = np.argsort(values)[::-1]\n",
    "        values   = values[sort_idx]\n",
    "        vectors  = vectors[:, sort_idx]\n",
    "        \n",
    "        # store principal components & variance\n",
    "        self.components = vectors[:self.num_components]\n",
    "        self.variance_share = np.sum(values[:self.num_components]) / np.sum(values)\n",
    "    \n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform data\n",
    "        \"\"\"\n",
    "        \n",
    "        # data centering\n",
    "        X -= self.mean\n",
    "        \n",
    "        # decomposition\n",
    "        return np.dot(X, self.components.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df = pd.read_csv(\"cleaned_shifted_data.csv\")\n",
    "    \n",
    "oe = OneHotEncoder(sparse=False)\n",
    "encoded = oe.fit_transform(pd.DataFrame(df['Station']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_IITG ', 'x0_LGBI Airport ', 'x0_Pan Bazaar ',\n",
       "       'x0_Railway Colony '], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "one_hot_df = pd.DataFrame(encoded, columns=oe.get_feature_names())\n",
    "df = pd.concat([df, one_hot_df], axis=1)\n",
    "\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df['year'] = df['Timestamp'].dt.year\n",
    "df['month'] = df['Timestamp'].dt.month\n",
    "df['dayofweek'] = df['Timestamp'].dt.day_of_week\n",
    "\n",
    "drop_cols = [0,1,2,12,14,16]\n",
    "drop_cols = df.columns[drop_cols]\n",
    "df.drop(drop_cols,axis=1,inplace=True)\n",
    "\n",
    "X = df.drop('AQI_calculated_shifted',axis = 1)\n",
    "y = df['AQI_calculated_shifted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174762, 17) (174762,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.13953143,  37.03042904, -58.15373783, ...,  11.9386136 ,\n",
       "        -50.07669542,  13.07018644],\n",
       "       [ -0.93831225,  36.90182928, -58.03797556, ...,  12.23933133,\n",
       "        -49.83941661,   9.99124985],\n",
       "       [ -0.61468367,  36.52321966, -58.09325186, ...,  12.29396125,\n",
       "        -50.31117511,  12.02783208],\n",
       "       ...,\n",
       "       [  8.37122392,  30.68552213,  -1.69996473, ..., -13.40586962,\n",
       "        -42.72771882,  39.25524837],\n",
       "       [  7.9843526 ,  32.26506977, -36.15169875, ...,   3.02848392,\n",
       "        -46.17233121,  36.62568228],\n",
       "       [ -8.65880869, -40.55730187, -46.25307474, ...,  -0.26595098,\n",
       "        -49.52923117,  34.90827246]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carry out PCA to reduce the number of features from 10 to 7 components\n",
    "pca = PCA(num_components = 7)  # initialize PCA object\n",
    "pca.fit(X) # fit PCA on old data\n",
    "X_pca = pca.transform(X) # transform datasets\n",
    "X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174762, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explained Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance: 0.9967\n"
     ]
    }
   ],
   "source": [
    "# check explained variance\n",
    "print(f\"Explained variance: {pca.variance_share:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
